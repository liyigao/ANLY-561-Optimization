{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by Yigao Li\n",
    "# Exercise 1\n",
    "Let $f({\\bf x})=||{\\bf y}-{\\bf x}||^2$, $g({\\bf x})={\\bf v}^T{\\bf x}-b$,  \n",
    "then $\\nabla f({\\bf x})=2({\\bf y}-{\\bf x})$, $\\nabla g({\\bf x})={\\bf v}$.  \n",
    "Suppose ${\\bf x}^*$ is a solution to this program, $\\exists\\lambda\\in\\mathbb{R}$ such that $\\nabla f({\\bf x}^*)=\\lambda\\nabla g({\\bf x}^*)$\n",
    "$$\\begin{cases}\n",
    "2({\\bf y}-{\\bf x}^*)+\\lambda{\\bf v}=0\\\\\n",
    "{\\bf v}^T{\\bf x}^*-b=0\\\\\n",
    "\\end{cases}$$\n",
    "Multiply ${\\bf v}^T$ to 1st equation,\n",
    "$$\\begin{aligned}\n",
    "{\\bf v}^T(2({\\bf y}-{\\bf x}^*)+\\lambda{\\bf v})&=0\\\\\n",
    "2{\\bf v}^T{\\bf y}-2{\\bf v}^T{\\bf x}^*+\\lambda{\\bf v}^T{\\bf v}&=0\\\\\n",
    "2{\\bf v}^T{\\bf y}-b+\\lambda{\\bf v}^2&=0\\\\\n",
    "\\lambda&=\\frac{b-2{\\bf v}^T{\\bf y}}{{\\bf v}^2}\\\\\n",
    "\\end{aligned}$$\n",
    "Plug $\\lambda$ back to the 1st equation to solve ${\\bf x}^*$,\n",
    "$$\\begin{aligned}\n",
    "2({\\bf y}-{\\bf x}^*)+\\frac{b-2{\\bf v}^T{\\bf y}}{{\\bf v}^2}{\\bf v}&=0\\\\\n",
    "{\\bf x}^*&={\\bf y}+\\frac{b-2{\\bf v}^T{\\bf y}}{2{\\bf v}^2}{\\bf v}\\\\\n",
    "\\end{aligned}$$\n",
    "  \n",
    "# Exercise 2\n",
    "Generate a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEKCAYAAAASByJ7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1cd958a7dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.32924648 -2.61122687]\n",
      " [-2.14881781 -2.66132898]\n",
      " [-2.39888678 -1.84413774]\n",
      " [-2.73297019 -1.49836405]\n",
      " [-2.71066696 -2.05648915]\n",
      " [-2.53908191 -1.88089376]\n",
      " [-2.5739314  -1.2852603 ]\n",
      " [-1.20475905 -1.82457755]\n",
      " [-1.72247153 -2.06903283]\n",
      " [-2.6241691  -2.58100533]]\n",
      "[[ 2.76539644  2.45389807]\n",
      " [ 2.6410187   2.2600055 ]\n",
      " [ 2.41580598  2.7224184 ]\n",
      " [ 2.17100951  1.23805708]\n",
      " [ 1.20394389  2.38105328]\n",
      " [ 2.39141596  1.70968543]\n",
      " [ 1.82941048  2.18431704]\n",
      " [ 1.9660156   1.28922637]\n",
      " [ 1.56681947  2.22672303]\n",
      " [ 1.67237459  1.41072205]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def random_circle(N):\n",
    "    x = np.reshape(rd.randn(N*2), (N, 2))\n",
    "    for i in range(N):\n",
    "        x[i,:] = x[i,:]/np.sqrt(np.sum(x[i,:]**2))\n",
    "    return x\n",
    "\n",
    "def random_radius(N, R=1):\n",
    "    r = rd.rand(N)\n",
    "    return R*np.sqrt(r) # This ensures uniform sampling from the disc\n",
    "    \n",
    "\n",
    "def random_disc(N, mu=[0,0], R=1):\n",
    "    x = random_circle(N)\n",
    "    r = random_radius(N, R=R)\n",
    "    for i in range(N):\n",
    "        x[i, :] = r[i] * x[i, :] + mu\n",
    "    return x\n",
    "\n",
    "N = 10\n",
    "\n",
    "X = random_disc(N, mu=[-2, -2])\n",
    "Y = random_disc(N, mu=[2, 2])\n",
    "\n",
    "plt.scatter(X[:,0], X[:,1])\n",
    "plt.scatter(Y[:,0], Y[:,1])\n",
    "plt.plot([-4, 4], [0, 0])\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#sys.setrecursionlimit(8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-20.   0.]\n",
      " [ 20.   0.]\n",
      " [ 10.   0.]\n",
      " [  0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "def backtracking(x0, dx, f, df0, alpha=0.2, beta=0.8, verbose=False):\n",
    "    '''\n",
    "    Backtracking for general functions with illustrations\n",
    "    :param x0: Previous point from backtracking, or initial guess\n",
    "    :param dx: Incremental factor for updating x0\n",
    "    :param f: Objective function\n",
    "    :param df0: Gradient of f at x0\n",
    "    :param alpha: Sloping factor of stopping criterion\n",
    "    :param beta: \"Agressiveness\" parameter for backtracking steps\n",
    "    :param verbose: Boolean for providing plots and data\n",
    "    :return: x1, the next iterate in backtracking\n",
    "    '''\n",
    "\n",
    "    # Note that the definition below requires that dx and df0 have the same shape\n",
    "    delta = alpha * np.sum(dx * df0) # A general, but memory intensive inner product\n",
    "    \n",
    "    t = 1 # Initialize t=beta^0\n",
    "    f0 = f(x0) # Evaluate for future use\n",
    "    x = x0 + dx # Initialize x_{0, inner}\n",
    "    fx = f(x)\n",
    "    \n",
    "    if verbose:\n",
    "        n=0\n",
    "        xs = [x]\n",
    "        fs = [fx]\n",
    "        ts = [1] * 3\n",
    "    \n",
    "    while (not np.isfinite(fx)) or f0 + delta * t < fx:\n",
    "        t = beta * t\n",
    "        x = x0 + t * dx\n",
    "        \n",
    "        if x[3] < 0:\n",
    "            break\n",
    "        \n",
    "        fx = f(x)\n",
    "    ###################################### \n",
    "    \n",
    "        if verbose:\n",
    "            n += 1\n",
    "            xs.append(x)\n",
    "            fs.append(fx)\n",
    "            ts.append(t)\n",
    "            ts.pop(0)\n",
    "            \n",
    "    if verbose:\n",
    "        # Display the function along the line search direction as a function of t\n",
    "        s = np.linspace(-0.1*ts[-1], 1.1*ts[0], 100)\n",
    "        xi = [0, 1.1*ts[0]]\n",
    "        fxi = [f0, f0 + 1.1*ts[0]*delta]   \n",
    "        y = np.zeros(len(s))\n",
    "        \n",
    "        for i in range(len(s)):\n",
    "            y[i] = f(x0 + s[i]*dx) # Slow for vectorized functions\n",
    "\n",
    "        plt.figure('Backtracking illustration')\n",
    "        arm, =plt.plot(xi, fxi, '--', label='Armijo Criterion')\n",
    "        fcn, =plt.plot(s, y, label='Objective Function')\n",
    "        plt.plot([s[0], s[-1]], [0, 0], 'k--')\n",
    "        pts =plt.scatter(ts, [0 for p in ts], label='Backtracking points for n=%d, %d, %d' % (n, n+1, n+2))\n",
    "        plt.scatter(ts, [f(x0 + q*dx) for q in ts] , label='Backtracking values for n=%d, %d, %d' % (n, n+1, n+2))\n",
    "        init =plt.scatter([0], [f0], color='black', label='Initial point')\n",
    "        plt.xlabel('$t$')\n",
    "        plt.ylabel('$f(x^{(k)}+t\\Delta x^{(k+1)})$')\n",
    "        plt.legend(handles=[arm, fcn, pts, init])\n",
    "        plt.show()\n",
    "        \n",
    "        return x, xs, fs\n",
    "    \n",
    "    else:\n",
    "        return x\n",
    "\n",
    "fun = lambda a: a[3]\n",
    "dfun = lambda a: np.array([0,0,0,1])\n",
    "alpha = 0.2\n",
    "beta = 0.8\n",
    "lb1 = lambda a: fun(a)\n",
    "dlb1 = lambda a: dfun(a)\n",
    "for x in X:\n",
    "    h = lambda a: 1+(np.dot(a[:2],x)-a[2])-a[3]\n",
    "    dh = lambda a :np.array([x[0],x[1],-1,-1])\n",
    "    lb1 = lambda a: lb1(a) - np.log(-h(a))\n",
    "    dlb1 = lambda a: dlb1(a) - dh(a)/h(a)\n",
    "for y in Y:\n",
    "    h = lambda a: 1-(np.dot(a[:2],y)-a[2])-a[3]\n",
    "    dh = lambda a: np.array([-y[0],-y[1],1,-1])\n",
    "    lb1 = lambda a: lb1(a) - np.log(-h(a))\n",
    "    dlb1 = lambda a: dlb1(a) - dh(a)/h(a)\n",
    "\n",
    "# Let initial z=0\n",
    "x1 = np.zeros((4, 2))\n",
    "x1[:,0] = np.array([-20,20,10,0])\n",
    "#dx = -dlb1(x1[:,0])\n",
    "#x1[:, 1], xs, fs = backtracking(x1[:,0], dx, lb1, -dx, alpha=alpha, beta=beta, verbose=True)\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "(Recursion is set at 8000 but it still exceeds maximum recursion limit. This code should get a least a $({\\bf v},b,z)$ such that $z<0$)  \n",
    "  \n",
    "(b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "[[ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "[[ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "[[ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "[[ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "fun = lambda a: (a[0]**2+a[1]**2)/2\n",
    "dfun = lambda a: np.array([2*a[0],2*a[1],0])\n",
    "alpha = 0.1\n",
    "beta = 0.5\n",
    "lb1 = lambda a: fun(a)\n",
    "dlb1 = lambda a: dfun(a)\n",
    "for x in X:\n",
    "    h = lambda a: 1+(np.dot(a[:2],x)-a[2])\n",
    "    dh = lambda a :np.array([x[0],x[1],-1])\n",
    "    lb1 = lambda a: lb1(a) - np.log(-h(a))\n",
    "    dlb1 = lambda a: dlb1(a) - dh(a)/h(a)\n",
    "for y in Y:\n",
    "    h = lambda a: 1-(np.dot(a[:2],y)-a[2])\n",
    "    dh = lambda a: np.array([-y[0],-y[1],1])\n",
    "    lb1 = lambda a: lb1(a) - np.log(-h(a))\n",
    "    dlb1 = lambda a: dlb1(a) - dh(a)/h(a)\n",
    "a = x1[:3,1]\n",
    "x1 = np.zeros((3,3))\n",
    "x1[:,0] = a\n",
    "#x1[:, 1], xs, fs = backtracking(x1[:,0], -dlb1(x1[:,0]), lb1, dlb1(x1[:,0]), alpha=alpha, beta=beta, verbose=True)\n",
    "#x1[:, 2], xs, fs = backtracking(x1[:, 1], -dlb1(x1[:,1]), lb1, dlb1(x1[:,1]), alpha=alpha, beta=beta, verbose=True)\n",
    "print(x1)\n",
    "lb2 = lambda a: fun(a)\n",
    "dlb2 = lambda a: dfun(a)\n",
    "for x in X:\n",
    "    h = lambda a: 1+(np.dot(a[:2],x)-a[2])\n",
    "    dh = lambda a :np.array([x[0],x[1],-1])\n",
    "    lb2 = lambda a: lb2(a) - 0.1*np.log(-h(a))\n",
    "    dlb2 = lambda a: dlb2(a) - 0.1*dh(a)/h(a)\n",
    "for y in Y:\n",
    "    h = lambda a: 1-(np.dot(a[:2],y)-a[2])\n",
    "    dh = lambda a: np.array([-y[0],-y[1],1])\n",
    "    lb2 = lambda a: lb2(a) - 0.1*np.log(-h(a))\n",
    "    dlb2 = lambda a: dlb2(a) - 0.1*dh(a)/h(a)\n",
    "x2 = np.zeros((3,3))\n",
    "x2[:,0] = x1[:,2]\n",
    "#x2[:, 1], xs, fs = backtracking(x2[:,0], -dlb2(x2[:,0]), lb2, dlb2(x2[:,0]), alpha=alpha, beta=beta, verbose=True)\n",
    "#x2[:, 2], xs, fs = backtracking(x2[:, 1], -dlb2(x2[:,1]), lb2, dlb2(x2[:,1]), alpha=alpha, beta=beta, verbose=True)\n",
    "print(x2)\n",
    "lb3 = lambda a: fun(a)\n",
    "dlb3 = lambda a: dfun(a)\n",
    "for x in X:\n",
    "    h = lambda a: 1+(np.dot(a[:2],x)-a[2])\n",
    "    dh = lambda a :np.array([x[0],x[1],-1])\n",
    "    lb3 = lambda a: lb3(a) - 0.01*np.log(-h(a))\n",
    "    dlb3 = lambda a: dlb3(a) - 0.01*dh(a)/h(a)\n",
    "for y in Y:\n",
    "    h = lambda a: 1-(np.dot(a[:2],y)-a[2])\n",
    "    dh = lambda a: np.array([-y[0],-y[1],1])\n",
    "    lb3 = lambda a: lb3(a) - 0.01*np.log(-h(a))\n",
    "    dlb3 = lambda a: dlb3(a) - 0.01*dh(a)/h(a)\n",
    "x3 = np.zeros((3,3))\n",
    "x3[:,0] = x2[:,2]\n",
    "#x3[:, 1], xs, fs = backtracking(x3[:,0], -dlb3(x3[:,0]), lb3, dlb3(x3[:,0]), alpha=alpha, beta=beta, verbose=True)\n",
    "#x3[:, 2], xs, fs = backtracking(x3[:, 1], -dlb3(x3[:,1]), lb3, dlb3(x3[:,1]), alpha=alpha, beta=beta, verbose=True)\n",
    "print(x3)\n",
    "lb4 = lambda a: fun(a)\n",
    "dlb4 = lambda a: dfun(a)\n",
    "for x in X:\n",
    "    h = lambda a: 1+(np.dot(a[:2],x)-a[2])\n",
    "    dh = lambda a :np.array([x[0],x[1],-1])\n",
    "    lb4 = lambda a: lb4(a) - 0.001*np.log(-h(a))\n",
    "    dlb4 = lambda a: dlb4(a) - 0.001*dh(a)/h(a)\n",
    "for y in Y:\n",
    "    h = lambda a: 1-(np.dot(a[:2],y)-a[2])\n",
    "    dh = lambda a: np.array([-y[0],-y[1],1])\n",
    "    lb4 = lambda a: lb4(a) - 0.001*np.log(-h(a))\n",
    "    dlb4 = lambda a: dlb4(a) - 0.001*dh(a)/h(a)\n",
    "x4 = np.zeros((3,3))\n",
    "x4[:,0] = x3[:,2]\n",
    "#x4[:, 1], xs, fs = backtracking(x4[:,0], -dlb4(x4[:,0]), lb4, dlb4(x4[:,0]), alpha=alpha, beta=beta, verbose=True)\n",
    "#x4[:, 2], xs, fs = backtracking(x4[:, 1], -dlb4(x4[:,1]), lb4, dlb4(x4[:,1]), alpha=alpha, beta=beta, verbose=True)\n",
    "print(x4)\n",
    "lb5 = lambda a: fun(a)\n",
    "dlb5 = lambda a: dfun(a)\n",
    "for x in X:\n",
    "    h = lambda a: 1+(np.dot(a[:2],x)-a[2])\n",
    "    dh = lambda a :np.array([x[0],x[1],-1])\n",
    "    lb5 = lambda a: lb5(a) - 0.0001*np.log(-h(a))\n",
    "    dlb5 = lambda a: dlb5(a) - 0.0001*dh(a)/h(a)\n",
    "for y in Y:\n",
    "    h = lambda a: 1-(np.dot(a[:2],y)-a[2])\n",
    "    dh = lambda a: np.array([-y[0],-y[1],1])\n",
    "    lb5 = lambda a: lb5(a) - 0.0001*np.log(-h(a))\n",
    "    dlb5 = lambda a: dlb5(a) - 0.0001*dh(a)/h(a)\n",
    "x5 = np.zeros((3,3))\n",
    "x5[:,0] = x4[:,2]\n",
    "#x5[:, 1], xs, fs = backtracking(x5[:,0], -dlb5(x5[:,0]), lb5, dlb5(x5[:,0]), alpha=alpha, beta=beta, verbose=True)\n",
    "#x5[:, 2], xs, fs = backtracking(x5[:, 1], -dlb5(x5[:,1]), lb5, dlb5(x5[:,1]), alpha=alpha, beta=beta, verbose=True)\n",
    "print(x5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
