# ANLY 561 Optimization

This course focuses on common mathematical optimization paradigms, efficient algorithmic techniques, and important Data Science applications of optimization over Euclidean spaces, with an emphasis on training Deep Neural Networks. Convex and non-convex paradigms are considered, and algorithmic techniques include line searches, gradient descent, Newton's method, the log-barrier interior point method, and stochastic gradient descent. The course builds up to techniques for training Deep Neural Networks by introducing least-squares regression, logistic regression, and support vector machines. The course concludes with a selection of applications of optimization in Data Science (which may include Adversarial Training, Clustering, Community Detection, Dimension Reduction, Expectation Maximization, Recurrent Neural Networks, Spectral Clustering, or Visualizations depending upon student interest and time).

## Topics

- **Univariate Optimization**: Necessary and Sufficient Conditions for Optimality, Steepest Descent, Back-tracking, Newton's Method
- **Multivariable Calculus**: Multivariate Functions and Derivatives, Gradients, Hessians, Jacobians, Chain Rules, Implicit Function Theorems
- **Unconstrained Optimization**: Necessary and Sufficient Conditions for Optimality, Line Searches, Gradient Descent, Newton's Method, Least-Squares Regression, Maximum Likelihood Principle and Logistic Regression
- **Constrained Optimization**: Feasibility, Necessary Conditions for Optimality and Lagrange Multipliers, Constraint Qualifications and KKT Conditions, Principal Component Analysis
- **Convex Programming**: Convex and Affine Functions, Linear Programs, Slater's Condition, Log Barrier Interior Point Method, Support Vector Machines
- **Advanced Algorithms**: Momentum, Stochastic Gradient Descent, Broyden-Fletcher-Goldfarb-Shanno Algorithm, Adam Algorithm
- **Deep Neural Networks**: Basics of Artificial Neural Networks, Activation Functions, Loss Functions, Back-Propagation, Regularization Techniques
- **Convolutional Neural Networks**: 2D Discrete Convolutions, Max-Pooling, Tensors, Deep Convolutional Neural Networks, MNIST Digit Classification
